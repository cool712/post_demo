<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
  <title>Pose Detection Pro</title>
  <style>
    html, body { margin: 0; padding: 0; width: 100%; height: 100%; background: black; overflow: hidden; }
    video, canvas { position: absolute; inset: 0; width: 100%; height: 100%; object-fit: cover; }
    
    /* ⭐ 关键：修复后的镜像样式 */
    video.mirror, canvas.mirror {
      transform: scaleX(-1);
      -webkit-transform: scaleX(-1);
    }

    canvas { pointer-events: none; z-index: 5; }
    #tip { position: absolute; top: 12px; left: 12px; color: #4ec9b0; font-size: 14px; font-family: monospace; z-index: 10; background: rgba(0,0,0,0.5); padding: 4px 8px; border-radius: 4px; }
  </style>
</head>
<body>
  <div id="tip">Initializing...</div>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>

  <script type="module">
    import { PoseLandmarker, FilesetResolver } from "/mediapipe/tasks-vision/vision_bundle.js";

    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const tip = document.getElementById("tip");

    let poseLandmarker = null;
    let running = false;
    let currentFacingMode = "user"; 

    // --- ⭐ 核心：供 Flutter 调用的切换函数 ---
    window.toggleCamera = async function() {
      currentFacingMode = (currentFacingMode === "user") ? "environment" : "user";
      await startCamera();
      return currentFacingMode; // 返回给 Flutter 用于更新 UI
    };

    // --- ⭐ 核心：健壮的摄像头启动逻辑 ---
    async function startCamera() {
      running = false; 
      tip.textContent = "Hardware Switching...";

      // 1. 彻底释放旧硬件资源
      if (video.srcObject) {
        const tracks = video.srcObject.getTracks();
        tracks.forEach(track => {
          track.stop();
          track.enabled = false;
        });
        video.srcObject = null;
      }

      // 2. 延迟 300ms 避开硬件冲突
      await new Promise(r => setTimeout(r, 300));

      const constraints = [
        { video: { facingMode: { exact: currentFacingMode }, width: { ideal: 1280 } } },
        { video: { facingMode: currentFacingMode, width: { ideal: 640 } } },
        { video: true }
      ];

      for (const constraint of constraints) {
        try {
          const stream = await navigator.mediaDevices.getUserMedia(constraint);
          video.srcObject = stream;
          
          // 3. 处理镜像显示
          if (currentFacingMode === "user") {
            video.classList.add("mirror");
            canvas.classList.add("mirror");
          } else {
            video.classList.remove("mirror");
            canvas.classList.remove("mirror");
          }

          await new Promise(r => video.onloadedmetadata = r);
          await video.play();

          // 4. 重设画布尺寸（确保后置摄像头捕捉不偏移）
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          
          running = true;
          tip.textContent = `Active: ${currentFacingMode}`;
          return;
        } catch (e) {
          console.warn("Retry failed:", e);
        }
      }
      tip.textContent = "Camera Switch Failed";
    }

    /* --- AI 逻辑与绘图 --- */
    async function initPose() {
      const vision = await FilesetResolver.forVisionTasks("/mediapipe/tasks-vision/wasm");
      poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
        baseOptions: { modelAssetPath: "/mediapipe/model/pose_landmarker_lite.task", delegate: "GPU" },
        runningMode: "VIDEO", numPoses: 1
      });
      tip.textContent = "AI Ready";
      requestAnimationFrame(loop);
    }

    function loop(ts) {
      if (running && poseLandmarker) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        const result = poseLandmarker.detectForVideo(video, ts);
        if (result.landmarks && result.landmarks[0]) {
          drawPose(result.landmarks[0]);
        }
      }
      requestAnimationFrame(loop);
    }

    function drawPose(lm) {
      ctx.save();
      ctx.strokeStyle = "#4ec9b0"; ctx.lineWidth = 3;
      const bones = [[11,13],[13,15],[12,14],[14,16],[23,25],[25,27],[24,26],[26,28],[11,12],[23,24],[11,23],[12,24]];
      bones.forEach(([a,b]) => {
        const p1 = {x: lm[a].x * canvas.width, y: lm[a].y * canvas.height};
        const p2 = {x: lm[b].x * canvas.width, y: lm[b].y * canvas.height};
        ctx.beginPath(); ctx.moveTo(p1.x, p1.y); ctx.lineTo(p2.x, p2.y); ctx.stroke();
      });
      ctx.restore();
    }

    // 录制相关函数 (startRecord/stopAndUpload) 保持不变...
    window.startRecord = async function() { /* ...录制逻辑... */ };
    window.stopAndUpload = async function(url) { /* ...上传逻辑... */ };

    startCamera();
    initPose();
  </script>
</body>
</html>