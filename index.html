<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
  <title>Pose Pro Fast</title>

  <style>
    html, body {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;
      background: #000;
      overflow: hidden;
    }
    video, canvas {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
    }
    .mirror {
      transform: scaleX(-1);
    }
    #tip {
      position: absolute;
      top: 12px;
      left: 12px;
      z-index: 10;
      color: #4ec9b0;
      background: rgba(0,0,0,0.65);
      padding: 6px 10px;
      border-radius: 4px;
      font-family: monospace;
      font-size: 12px;
    }
  </style>
</head>

<body>
<div id="tip">Booting…</div>
<video id="video" autoplay playsinline muted></video>
<canvas id="canvas"></canvas>

<script type="module">
import { PoseLandmarker, FilesetResolver } from "/mediapipe/tasks-vision/vision_bundle.js";

/* ================= DOM ================= */
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const tip = document.getElementById("tip");

/* ================= 状态 ================= */
let poseLandmarker = null;
let vision = null;
let running = false;
let aiReady = false;
let facingMode = "user";

/* ================= 摄像头 ================= */
async function startCamera() {
  tip.textContent = "Camera starting…";
  if (video.srcObject) {
    video.srcObject.getTracks().forEach(t => t.stop());
  }

  const stream = await navigator.mediaDevices.getUserMedia({
    video: {
      facingMode,
      width: { ideal: 1280 },
      height: { ideal: 720 }
    }
  });

  video.srcObject = stream;
  await video.play();

  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;

  const mirror = facingMode === "user";
  video.classList.toggle("mirror", mirror);
  canvas.classList.toggle("mirror", mirror);

  running = true;
  tip.textContent = "Camera OK";

  // ⭐ 关键：摄像头 ready 后再初始化 AI
  setTimeout(initAI_CPU, 300);
}

/* ================= AI（CPU 快速启动） ================= */
async function initAI_CPU() {
  tip.textContent = "AI loading (CPU)…";

  vision = await FilesetResolver.forVisionTasks(
    "/mediapipe/tasks-vision/wasm"
  );

  poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
    baseOptions: {
      modelAssetPath: "/mediapipe/model/pose_landmarker_lite.task",
      delegate: "CPU"
    },
    runningMode: "VIDEO",
    numPoses: 1,
    minPoseDetectionConfidence: 0.4,
    minPosePresenceConfidence: 0.4,
    minTrackingConfidence: 0.4
  });

  // ⭐ warm-up（防首帧卡）
  poseLandmarker.detectForVideo(video, performance.now());

  aiReady = true;
  tip.textContent = "AI Ready";

  // ⭐ 后台切 GPU（不影响首屏）
  setTimeout(initAI_GPU, 3000);
}

/* ================= AI（GPU 提速） ================= */
async function initAI_GPU() {
  try {
    poseLandmarker.close();
    poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
      baseOptions: {
        modelAssetPath: "/mediapipe/model/pose_landmarker_lite.task",
        delegate: "GPU"
      },
      runningMode: "VIDEO",
      numPoses: 1
    });
    tip.textContent = "AI GPU Accelerated";
  } catch (e) {
    console.warn("GPU fallback to CPU");
  }
}

/* ================= 主循环 ================= */
function loop(ts) {
  requestAnimationFrame(loop);
  if (!running) return;

  ctx.clearRect(0, 0, canvas.width, canvas.height);
  if (!aiReady) return;

  const res = poseLandmarker.detectForVideo(video, ts);
  if (res.landmarks?.length) drawPose(res.landmarks[0]);
}
requestAnimationFrame(loop);

/* ================= 绘制 ================= */
function drawPose(lm) {
  ctx.save();
  ctx.strokeStyle = "#00ff7f";
  ctx.fillStyle = "#ffffff";
  ctx.lineWidth = 3;

  const bones = [
    [11,13],[13,15],[12,14],[14,16],
    [23,25],[25,27],[24,26],[26,28],
    [11,12],[23,24],[11,23],[12,24]
  ];

  bones.forEach(([a,b]) => line(lm[a], lm[b]));
  lm.forEach(p => point(p));

  angle(lm[11], lm[13], lm[15]);
  angle(lm[12], lm[14], lm[16]);
  angle(lm[23], lm[25], lm[27]);
  angle(lm[24], lm[26], lm[28]);

  ctx.restore();
}

function toCanvas(p) {
  return { x: p.x * canvas.width, y: p.y * canvas.height };
}
function line(a,b){
  const p1 = toCanvas(a), p2 = toCanvas(b);
  ctx.beginPath();
  ctx.moveTo(p1.x,p1.y);
  ctx.lineTo(p2.x,p2.y);
  ctx.stroke();
}
function point(p){
  const c = toCanvas(p);
  ctx.beginPath();
  ctx.arc(c.x,c.y,3,0,Math.PI*2);
  ctx.fill();
}
function angle(a,b,c){
  const A = toCanvas(a), B = toCanvas(b), C = toCanvas(c);
  const ab = {x:A.x-B.x,y:A.y-B.y};
  const cb = {x:C.x-B.x,y:C.y-B.y};
  const dot = ab.x*cb.x + ab.y*cb.y;
  const ang = Math.acos(dot/(Math.hypot(ab.x,ab.y)*Math.hypot(cb.x,cb.y))) * 180/Math.PI;
  ctx.font = "12px monospace";
  ctx.fillText(`${Math.round(ang)}°`, B.x+6, B.y-6);
}

/* ================= Flutter 接口 ================= */
window.toggleCamera = async () => {
  facingMode = facingMode === "user" ? "environment" : "user";
  await startCamera();
  return facingMode;
};

/* ================= 启动 ================= */
startCamera();
</script>
</body>
</html>
