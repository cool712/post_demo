<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
  <title>Pose Pro Fix</title>
  <style>
    html, body { margin: 0; padding: 0; width: 100%; height: 100%; background: #000; overflow: hidden; }
    video, canvas { position: absolute; inset: 0; width: 100%; height: 100%; object-fit: cover; }
    .mirror { transform: scaleX(-1); -webkit-transform: scaleX(-1); }
    #tip { 
      position: absolute; top: 15px; left: 15px; z-index: 100; 
      color: #4ec9b0; background: rgba(0,0,0,0.7); 
      padding: 5px 10px; border-radius: 4px; font-family: monospace; font-size: 11px;
    }
  </style>
</head>
<body>
  <div id="tip">System Initializing...</div>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>

  <script type="module">
    // 使用 CDN 确保资源 100% 加载，解决白屏
    import { PoseLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const tip = document.getElementById("tip");

    let poseLandmarker = null;
    let running = false;
    let currentFacingMode = "user"; 
    
    // 性能调优变量
    let frameCount = 0;
    let lastFpsCheck = 0;
    let fps = 0;

    /* ---------------- 摄像头启动逻辑 ---------------- */
    async function startCamera() {
      running = false;
      tip.textContent = "Hardware: Loading...";
      
      if (video.srcObject) {
        video.srcObject.getTracks().forEach(t => t.stop());
        video.srcObject = null;
      }

      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: currentFacingMode, width: { ideal: 1280 }, height: { ideal: 720 } }
        });
        video.srcObject = stream;
        
        // 镜像逻辑
        const needsMirror = currentFacingMode === "user";
        [video, canvas].forEach(el => el.classList.toggle("mirror", needsMirror));

        await video.play();
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        running = true;
        tip.textContent = `Cam: ${currentFacingMode} OK`;
        return currentFacingMode;
      } catch (err) {
        tip.textContent = "Cam Error: " + err.name;
        console.error(err);
      }
    }

    /* ---------------- AI 初始化 ---------------- */
    async function initAI() {
      try {
        const vision = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
        );
        poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
          baseOptions: { 
            modelAssetPath: "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task", 
            delegate: "GPU" 
          },
          runningMode: "VIDEO",
          numPoses: 1
        });
        tip.textContent = "AI Ready";
        requestAnimationFrame(loop);
      } catch (e) {
        tip.textContent = "AI Init Failed";
      }
    }

    /* ---------------- 核心循环 (包含性能监控) ---------------- */
    function loop(ts) {
      if (running && poseLandmarker) {
        // FPS 计算
        frameCount++;
        if (ts - lastFpsCheck > 1000) {
          fps = frameCount;
          tip.textContent = `FPS: ${fps} | Mode: ${currentFacingMode}`;
          frameCount = 0;
          lastFpsCheck = ts;
        }

        ctx.clearRect(0, 0, canvas.width, canvas.height);
        
        try {
          // 这里是 AI 识别核心
          const result = poseLandmarker.detectForVideo(video, ts);
          if (result && result.landmarks && result.landmarks[0]) {
            drawPose(result.landmarks[0]);
          }
        } catch (e) {
          // 防止单帧识别错误崩溃
        }
      }
      requestAnimationFrame(loop);
    }

    function drawPose(lm) {
      ctx.save();
      ctx.strokeStyle = "#4ec9b0";
      ctx.fillStyle = "#ffffff";
      ctx.lineWidth = 3;

      const bones = [
        [11,13],[13,15],[12,14],[14,16],
        [23,25],[25,27],[24,26],[26,28],
        [11,12],[23,24],[11,23],[12,24]
      ];

      bones.forEach(([a,b]) =>
        drawLine(toCanvas(lm[a]), toCanvas(lm[b]))
      );

      lm.forEach(p => drawPoint(toCanvas(p)));
      // ⭐ 四个关节角度
      drawAngle(lm[11], lm[13], lm[15]); // 左肘
      drawAngle(lm[12], lm[14], lm[16]); // 右肘
      drawAngle(lm[23], lm[25], lm[27]); // 左膝
      drawAngle(lm[24], lm[26], lm[28]); // 右膝
    

      ctx.restore();
    }
	  function drawAngle(a, b, c) {
      const angle = Math.round(calcAngle(a, b, c));
      const p = toCanvas(b);
      ctx.font = "12px monospace";
      ctx.fillText(`${angle}°`, p.x + 6, p.y - 6);
    }

    /* ---------------- Flutter 接口 ---------------- */
    window.toggleCamera = async function() {
      currentFacingMode = (currentFacingMode === "user") ? "environment" : "user";
      const res = await startCamera();
      return res;
    };

    // 启动顺序：先启相机，再开AI
    startCamera().then(initAI);
  </script>
</body>
</html>