<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
  <title>Pose Detection</title>

  <style>
    html, body {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;
      background: black;
      overflow: hidden;
    }

    video, canvas {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      transform: rotateY(180deg);
    }

    canvas { pointer-events: none; }

    .controls {
      position: absolute;
      bottom: 20px;
      left: 50%;
      transform: translateX(-50%);
      z-index: 10;
    }

    button {
      padding: 10px 14px;
      font-size: 15px;
      margin: 0 6px;
    }
  </style>
</head>

<body>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>

  <div class="controls">
    <button id="startBtn">START</button>
    <button id="switchBtn">SWITCH</button>
  </div>

  <script type="module">
    import {
      PoseLandmarker,
      FilesetResolver,
      DrawingUtils
    } from "https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0";

    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const drawUtils = new DrawingUtils(ctx);

    const startBtn = document.getElementById("startBtn");
    const switchBtn = document.getElementById("switchBtn");

    let poseLandmarker = null;
    let running = false;
    let facingMode = "user"; // user | environment

    /* 初始化 Pose */
    async function initPose() {
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
      );

      poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath:
            "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task",
          delegate: "GPU"
        },
        runningMode: "VIDEO",
        numPoses: 1
      });
    }

    /* 启动摄像头 */
    async function startCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode }
      });

      video.srcObject = stream;
      await video.play();
      await new Promise(r => video.onloadedmetadata = r);

      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      running = true;
      requestAnimationFrame(loop);
    }

    /* 停止摄像头 */
    function stopCamera() {
      running = false;
      video.srcObject?.getTracks().forEach(t => t.stop());
      video.srcObject = null;
      ctx.clearRect(0, 0, canvas.width, canvas.height);
    }

    /* 检测循环 */
    async function loop() {
      if (!running || !poseLandmarker) return;

      const result = await poseLandmarker.detectForVideo(
        video,
        performance.now()
      );

      ctx.clearRect(0, 0, canvas.width, canvas.height);

      for (const landmarks of result.landmarks) {
        drawUtils.drawLandmarks(landmarks, { radius: 4 });
        drawUtils.drawConnectors(
          landmarks,
          PoseLandmarker.POSE_CONNECTIONS
        );
      }

      requestAnimationFrame(loop);
    }

    /* 按钮逻辑 */
    initPose().then(() => {
      startBtn.onclick = async () => {
        if (!running) {
          startBtn.innerText = "STOP";
          await startCamera();
        } else {
          startBtn.innerText = "START";
          stopCamera();
        }
      };

      switchBtn.onclick = async () => {
        facingMode = facingMode === "user" ? "environment" : "user";
        if (running) {
          stopCamera();
          await startCamera();
        }
      };
    });
  </script>
</body>
</html>
