<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>MediaPipe Pose Landmarker Demo</title>
  <style>
    body {
      font-family: Roboto, Arial, sans-serif;
      margin: 1em;
      color: #3d3d3d;
    }
    video, canvas {
      max-width: 100%;
      height: auto;
      transform: rotateY(180deg);
    }
    #container {
      position: relative;
      width: 100%;
      max-width: 640px;
    }
    canvas {
      position: absolute;
      left: 0;
      top: 0;
      pointer-events: none;
      transform: rotateY(180deg);
    }
    button {
      margin: 5px 5px 10px 0;
    }
  </style>
</head>
<body>
  <h1>Pose detection using MediaPipe</h1>

  <div id="container">
    <button id="webcamButton">ENABLE WEBCAM</button>
    <button id="switchButton">SWITCH CAMERA</button>
    <video id="webcam" autoplay playsinline></video>
    <canvas id="output_canvas"></canvas>
  </div>

  <script type="module">
    import { PoseLandmarker, FilesetResolver, DrawingUtils } from "https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0";

    const video = document.getElementById("webcam");
    const canvas = document.getElementById("output_canvas");
    const ctx = canvas.getContext("2d");
    const drawingUtils = new DrawingUtils(ctx);
    const webcamButton = document.getElementById("webcamButton");
    const switchButton = document.getElementById("switchButton");

    let poseLandmarker;
    let runningMode = "IMAGE";
    let webcamRunning = false;
    let currentFacingMode = "user"; // "user" = 前置, "environment" = 后置

    // 初始化 PoseLandmarker
    async function createPoseLandmarker() {
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
      );

      poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task",
          delegate: "GPU"
        },
        runningMode,
        numPoses: 2
      });
    }

    createPoseLandmarker();

    async function startWebcam() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: currentFacingMode }
        });
        video.srcObject = stream;

        // 等待视频就绪
        await new Promise(resolve => {
          video.onloadedmetadata = () => resolve();
        });

        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        webcamRunning = true;
        webcamButton.innerText = "DISABLE WEBCAM";
        requestAnimationFrame(predictWebcam);
      } catch (err) {
        alert("摄像头访问被拒绝或设备不支持。");
        console.error(err);
      }
    }

    function stopWebcam() {
      if (video.srcObject) {
        video.srcObject.getTracks().forEach(track => track.stop());
        video.srcObject = null;
        ctx.clearRect(0, 0, canvas.width, canvas.height);
      }
      webcamRunning = false;
      webcamButton.innerText = "ENABLE WEBCAM";
    }

    webcamButton.addEventListener("click", () => {
      if (!webcamRunning) {
        startWebcam();
      } else {
        stopWebcam();
      }
    });

    switchButton.addEventListener("click", async () => {
      currentFacingMode = currentFacingMode === "user" ? "environment" : "user";
      if (webcamRunning) {
        stopWebcam();
        await startWebcam();
      }
    });

    let lastVideoTime = -1;
    async function predictWebcam() {
      if (!webcamRunning) return;

      if (runningMode === "IMAGE") {
        runningMode = "VIDEO";
        await poseLandmarker.setOptions({ runningMode: "VIDEO" });
      }

      if (video.currentTime !== lastVideoTime) {
        lastVideoTime = video.currentTime;
        const result = await poseLandmarker.detectForVideo(video, performance.now());
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        for (const landmark of result.landmarks) {
          drawingUtils.drawLandmarks(landmark);
          drawingUtils.drawConnectors(landmark, PoseLandmarker.POSE_CONNECTIONS);
        }
      }

      requestAnimationFrame(predictWebcam);
    }
  </script>
</body>
</html>
